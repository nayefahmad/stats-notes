{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Regularized regression and random forests as tools for EDA<br>\n", "2022-12-09"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Overview"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Data: Ten baseline variables (age, sex, body mass index, average<br>\n", "blood pressure, and six blood serum measurements) were obtained for each of<br>\n", "n=n442 diabetes patients."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Each of these 10 feature variables have been mean centered and scaled by the<br>\n", "standard deviation times the square root of n_samples (i.e. the sum of squares of<br>\n", "each column totals 1). This kind of standardization is required before using Lasso<br>\n", "and ridge regression (and other regularization-based methods), and in general is a<br>\n", "good idea when we want to determine predictor importance. [2][3][4]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Choosing between ridge, lasso, and elastic net: ridge is a good default unless you<br>\n", "suspect that only a few features are useful. Elastic net is preferred over lasso<br>\n", "because lasso may behave erratically when p > n or several features are strongly<br>\n", "correlated. [5]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## References"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1. [scikit-learn doc on diabetes dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)  # noqa<br>\n", "<br>\n", "2. [When and Why to Standardize Your Data - Builtin.com](https://builtin.com/data-science/when-and-why-standardize-your-data)  # noqa<br>\n", "<br>\n", "3. [When and why to standardize a variable - Listendata.com](https://www.listendata.com/2017/04/how-to-standardize-variable-in-regression.html)  # noqa<br>\n", "<br>\n", "4. HOML book, p136<br>\n", "<br>\n", "5. HOML book, p140<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from typing import Type"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import seaborn as sns\n", "import sklearn.linear_model._base\n", "from sklearn.datasets import load_diabetes, load_iris\n", "from sklearn.linear_model import ElasticNetCV, Lasso, LassoCV, LinearRegression, RidgeCV\n", "from sklearn.model_selection import cross_val_score"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["diabetes = load_diabetes()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_diabetes = pd.concat(\n", "    [pd.DataFrame(diabetes[\"data\"]), pd.DataFrame(diabetes[\"target\"])], axis=1\n", ")\n", "num_x_cols = 10\n", "x_col_names = [f\"x_0{num}\" for num in range(1, 10)] + [\n", "    f\"x_{num}\" for num in range(10, 11)\n", "]\n", "df_diabetes.columns = x_col_names + [\"y\"]\n", "df_diabetes.reset_index(drop=False, inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_diabetes.head()\n", "df_diabetes.shape\n", "df_diabetes.describe()\n", "df_diabetes.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Plots"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_melted = df_diabetes.melt(id_vars=[\"index\"], value_vars=[col for col in df_diabetes])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reprint_plots = True\n", "if reprint_plots:\n", "    title = \"Distribution of predictor variables\"\n", "    sns.displot(\n", "        df_melted.query('variable != \"y\"'),\n", "        x=\"value\",\n", "        hue=\"variable\",\n", "        kind=\"kde\",\n", "    )\n", "    plt.title(title)\n", "    plt.show()\n", "    assert df_diabetes[\"x_02\"].nunique() == 2\n", "    title = \"Boxplot of y vs. categorical variable, x_02\"\n", "    sns.boxplot(df_diabetes[[\"x_02\", \"y\"]], x=\"x_02\", y=\"y\")\n", "    plt.title(title)\n", "    plt.show()\n", "    df_diabetes.groupby(\"x_02\")[\"y\"].mean()\n", "    title = \"Distribution of response variable\"\n", "    sns.displot(\n", "        df_melted.query('variable == \"y\"'),\n", "        x=\"value\",\n", "        hue=\"variable\",\n", "        kind=\"kde\",\n", "    )\n", "    plt.title(title)\n", "    plt.show()\n", "    title = \"Response vs each predictor\"\n", "    fig = plt.figure(figsize=(9, 9))\n", "    for idx, x_var in enumerate(df_diabetes[x_col_names]):\n", "        ax = plt.subplot(5, 2, idx + 1)\n", "        ax.plot(df_diabetes[x_var], df_diabetes[\"y\"], \"o\", mfc=\"none\")\n", "        ax.set_ylabel(\"y\")\n", "        ax.set_xlabel(x_var)\n", "        ax.grid(True)\n", "    plt.suptitle(title, fontsize=14)\n", "    fig.tight_layout()\n", "    fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Analysis focusing on y, x_07, and x_02"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Assume that we want to interpret the coefficient of x_07<br>\n", "- Goal: show that regression allows us to adjust for x_02 and give a better<br>\n", "  estimate of the coefficient."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reprint_plots = True\n", "if reprint_plots:\n", "    x_var = \"x_07\"\n", "    title = f\"Response vs {x_var}, by levels of x_02\"\n", "    ax = sns.scatterplot(\n", "        df_diabetes[[\"x_02\", x_var, \"y\"]],\n", "        x=x_var,\n", "        y=\"y\",\n", "        hue=\"x_02\",\n", "        marker=\"$\\circ$\",  # noqa\n", "        ec=\"face\",\n", "    )\n", "    box = ax.get_position()\n", "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n", "    ax.legend(bbox_to_anchor=(1, 0.5))\n", "    ax.set_title(title)\n", "    plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Models"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_lm = LinearRegression()\n", "model_ridge = RidgeCV(cv=5)\n", "model_lasso = LassoCV(cv=5)\n", "model_elastic_net = ElasticNetCV(cv=5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = {\n", "    1: model_lm,\n", "    2: model_ridge,\n", "    3: model_lasso,\n", "    4: model_elastic_net,\n", "}\n", "predictor_sets = [\"all\", \"x_07\", \"x_07_x_02\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def identify_predictors(predictor_str: str, df: pd.DataFrame) -> pd.DataFrame:\n", "    if predictor_str == \"all\":\n", "        return df.drop(columns=[\"index\", \"y\"])\n", "    elif predictor_str == \"x_07\":\n", "        return df[[\"x_07\"]]\n", "    elif predictor_str == \"x_07_x_02\":\n", "        return df[[\"x_07\", \"x_02\"]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def model_params_and_hyperparams(\n", "    model: Type[sklearn.linear_model._base.LinearModel], df_X: pd.DataFrame\n", "):\n", "    if type(model) == LinearRegression:\n", "        model.alpha_ = None\n", "    alpha = model.alpha_\n", "    coefs = model.coef_.squeeze().tolist()\n", "    coefs = [coefs] if type(coefs) == float else coefs\n", "    var_names = df_X.columns.to_list()\n", "    coefs_named = [coef_name for coef_name in zip(var_names, coefs)]\n", "    coefs_named = pd.DataFrame(coefs_named).rename(columns={0: \"variable\", 1: \"coeff\"})\n", "    intercept = model.intercept_\n", "    return alpha, coefs_named, intercept"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = {}\n", "for model_id, model in models.items():\n", "    for predictors in predictor_sets:\n", "        df_X = identify_predictors(predictors, df_diabetes)\n", "        X = df_X.to_numpy()\n", "        y = df_diabetes[[\"y\"]].to_numpy()\n", "        model.fit(X, y)\n", "        score = model.score(X, y)\n", "        alpha, coefs_named, intercept = model_params_and_hyperparams(model, df_X)\n", "        results[f\"{model_id}-{model} with predictors: {predictors}\"] = {\n", "            \"alpha\": alpha,\n", "            \"score\": score,\n", "            \"coeffs\": coefs_named,\n", "            \"intercept\": intercept,\n", "        }"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(results)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Tests"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Is the .score() method of e.g. `LassoCV` giving us a cross-validated r-squared?<br>\n", "[See this](https://stats.stackexchange.com/questions/350484/why-is-r-squared-not-a-good-measure-for-regressions-fit-using-lasso)  # noqa"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Also see ISLR, p243."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_lasso_cross_validated_r_squared():\n", "    assert type(models[3]) == sklearn.linear_model._coordinate_descent.LassoCV\n", "    X, y = load_iris(return_X_y=True)\n", "    model = Lasso(alpha=models[3].alpha_)\n", "    model.fit(X, y)\n", "    scores = cross_val_score(model, X, y, cv=5, scoring=\"r2\")\n", "    try:\n", "        assert scores.mean() == model.score(X, y)\n", "    except AssertionError as e:\n", "        print(f\"AssertionError: {e}\")\n", "        print(f\"Difference in score = {scores.mean() - models[3].score(X, y)}\")\n", "    print(\"done\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_lasso_cross_validated_r_squared()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}